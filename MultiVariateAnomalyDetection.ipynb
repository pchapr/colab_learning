{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pchapr/colab_learning/blob/main/MultiVariateAnomalyDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYGmDBEN_EEW"
      },
      "source": [
        "#1 Using data/finanacial_data.csv would like to build a deep learning model to identify anomolies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAtKQk5TP1zn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import mean_squared_error, precision_recall_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense, Embedding, Concatenate, Reshape\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m step_counts = step_counts.sort_values(by=\u001b[33m'\u001b[39m\u001b[33mstep\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Create the plot\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mplt\u001b[49m.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m6\u001b[39m))  \u001b[38;5;66;03m# Adjust figure size as needed\u001b[39;00m\n\u001b[32m     13\u001b[39m plt.plot(step_counts[\u001b[33m'\u001b[39m\u001b[33mstep\u001b[39m\u001b[33m'\u001b[39m], step_counts[\u001b[33m'\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m'\u001b[39m], marker=\u001b[33m'\u001b[39m\u001b[33mo\u001b[39m\u001b[33m'\u001b[39m, linestyle=\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     14\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mTotal Count of Rows Grouped by Step\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "# Read the CSV file into a pandas DataFrame\n",
        "financial_data_df_orig = pd.read_csv('data/financial_data.csv')\n",
        "#financial_data_df_orig = financial_data_df_orig.sample(n=200000, random_state=42).reset_index(drop=True)\n",
        "# plot toal count of roes group by step\n",
        "# Group the DataFrame by the 'step' column and count the number of rows in each group\n",
        "step_counts = financial_data_df_orig.groupby('step').size().reset_index(name='count')\n",
        "\n",
        "# Sort by step for a logical progression in the plot (optional, but usually helpful)\n",
        "step_counts = step_counts.sort_values(by='step')\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(12, 6))  # Adjust figure size as needed\n",
        "plt.plot(step_counts['step'], step_counts['count'], marker='o', linestyle='-')\n",
        "plt.title('Total Count of Rows Grouped by Step')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Total Count')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability if there are many steps\n",
        "plt.tight_layout()  # Adjust layout to prevent labels from overlapping\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc2DBc1sApTk",
        "outputId": "ef97f260-f72c-441d-a934-ff22a6bea849"
      },
      "outputs": [],
      "source": [
        "# Display the first few rows of the DataFrame to understand its structure\n",
        "#print(financial_data_df.head())\n",
        "\n",
        "# Get basic information about the DataFrame (column types, non-null values)\n",
        "#print(financial_data_df.info())\n",
        "\n",
        "# Get descriptive statistics of the numerical columns\n",
        "#print(financial_data_df.describe())\n",
        "financial_data_df_orig.iloc[0]\n",
        "#financial_data_df_orig.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Separate features (X) and target (y)\n",
        "financial_data_df = financial_data_df_orig.drop(['isFraud', 'isFlaggedFraud'], axis=1)  # Drop the target variables\n",
        "y = financial_data_df_orig ['isFraud']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "financial_data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUyEjXwAE54g",
        "outputId": "aa223a76-920b-4ef8-9472-d14d2faa9584"
      },
      "outputs": [],
      "source": [
        "financial_data_df['nameDest'].unique().size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PB-iZigBRJ_"
      },
      "outputs": [],
      "source": [
        "numerical_features = ['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
        "categorical_features = ['type']\n",
        "origin_dest_features = ['nameOrig', 'nameDest']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LeiF9vhwQf9O",
        "outputId": "db77f7be-3db1-494b-d018-7001f4d205b0"
      },
      "outputs": [],
      "source": [
        "for feature in numerical_features:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(financial_data_df['step'], financial_data_df[feature], alpha=0.5, s=1)\n",
        "    plt.title(f'Distribution of {feature} Across Steps')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel(feature)\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZtQBv_MQB8b"
      },
      "outputs": [],
      "source": [
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "financial_data_df[numerical_features] = scaler.fit_transform(financial_data_df[numerical_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "efmdk-XwQNOR",
        "outputId": "1d99e17e-cd69-4652-b313-d665763ba31c"
      },
      "outputs": [],
      "source": [
        "# prompt: Plot the numeric fields distribution across steps\n",
        "\n",
        "# Plot distribution of numerical features across steps\n",
        "for feature in numerical_features:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(financial_data_df['step'], financial_data_df[feature], alpha=0.5, s=1)\n",
        "    plt.title(f'Distribution of {feature} Across Steps')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel(feature)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "ptNpdGyoAugn",
        "outputId": "9efb9ff2-cc50-45bd-ddd3-1b2b158a8e05"
      },
      "outputs": [],
      "source": [
        "# prompt: Chart the type distribuction across steps as area\n",
        "\n",
        "# Plot distribution of categorical features across steps\n",
        "plt.figure(figsize=(12, 7))\n",
        "financial_data_df.groupby('step')['type'].value_counts().unstack().plot(kind='area', stacked=True, ax=plt.gca())\n",
        "plt.title('Distribution of Transaction Types Across Steps')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Number of Transactions')\n",
        "plt.legend(title='Transaction Type')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j1D8aU6RXut"
      },
      "outputs": [],
      "source": [
        "# One-hot encode 'type'\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "type_encoded = encoder.fit_transform(financial_data_df[['type']])\n",
        "type_df = pd.DataFrame(type_encoded, columns=encoder.get_feature_names_out(['type']))\n",
        "financial_data_df = pd.concat([financial_data_df.drop('type', axis=1).reset_index(drop=True), type_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "B0JZ3YVSSl3G",
        "outputId": "ce46ade7-1225-4f1b-c4fc-dc1e484f029c"
      },
      "outputs": [],
      "source": [
        "financial_data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "KlrBETCaSWDy",
        "outputId": "c0d11976-83aa-48e6-c0b3-87adc7322a04"
      },
      "outputs": [],
      "source": [
        "# prompt: Chart the type distribuction across steps as area\n",
        "\n",
        "# Plot distribution of categorical features across steps\n",
        "plt.figure(figsize=(12, 7))\n",
        "financial_data_df.groupby('step')['type_CASH_IN'].value_counts().unstack().plot(kind='area', stacked=True, ax=plt.gca())\n",
        "financial_data_df.groupby('step')['type_CASH_OUT'].value_counts().unstack().plot(kind='area', stacked=True, ax=plt.gca())\n",
        "financial_data_df.groupby('step')['type_DEBIT'].value_counts().unstack().plot(kind='area', stacked=True, ax=plt.gca())\n",
        "financial_data_df.groupby('step')['type_PAYMENT'].value_counts().unstack().plot(kind='area', stacked=True, ax=plt.gca())\n",
        "financial_data_df.groupby('step')['type_TRANSFER'].value_counts().unstack().plot(kind='area', stacked=True, ax=plt.gca())\n",
        "plt.title('Distribution of Transaction Types Across Steps')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Number of Transactions')\n",
        "plt.legend(title='Transaction Type')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Wn5Md2jUhF7"
      },
      "outputs": [],
      "source": [
        "# Tokenizing the text field for deeplearning model training\n",
        "max_origin_features = financial_data_df['nameOrig'].nunique()\n",
        "origin_tokenizer = Tokenizer(num_words=max_origin_features)\n",
        "origin_tokenizer.fit_on_texts(financial_data_df['nameOrig'])\n",
        "origin_sequences = origin_tokenizer.texts_to_sequences(financial_data_df['nameOrig'])\n",
        "padded_origin = pad_sequences(origin_sequences, maxlen=1) # Still treat as sequence of length 1 at each step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "S4SzTr_iVLmH",
        "outputId": "144883ce-d37e-4279-d537-21097f087ce2"
      },
      "outputs": [],
      "source": [
        "financial_data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qU-OfDjtUyHg"
      },
      "outputs": [],
      "source": [
        "max_dest_features = financial_data_df['nameDest'].nunique()\n",
        "dest_tokenizer = Tokenizer(num_words=max_dest_features)\n",
        "dest_tokenizer.fit_on_texts(financial_data_df['nameDest'])\n",
        "dest_sequences = dest_tokenizer.texts_to_sequences(financial_data_df['nameDest'])\n",
        "padded_dest = pad_sequences(dest_sequences, maxlen=1) # Still treat as sequence of length 1 at each step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpFavoHrZa5p"
      },
      "outputs": [],
      "source": [
        "# Combine features for sequence generation\n",
        "feature_columns = numerical_features + list(type_df.columns)\n",
        "X = financial_data_df[feature_columns].values\n",
        "origin_ids = padded_origin.reshape(-1, 1)\n",
        "dest_ids = padded_dest.reshape(-1, 1)\n",
        "y_fraud = financial_data_df_orig['isFraud'].values\n",
        "\n",
        "# 3. Sequence Generation\n",
        "sequence_length = 20 # Choose an appropriate sequence length\n",
        "batch_size = 128\n",
        "y_fraud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WUK4xQmYGOE"
      },
      "outputs": [],
      "source": [
        "# Combine features for sequence generation (now including tokenized IDs)\n",
        "def create_sequences_with_ids(data_numerical_encoded, data_type_encoded, origin_ids, dest_ids, y, sequence_length):\n",
        "    # ... (Logic to create sequences where each step includes numerical, type, origin_id, dest_id) ...\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    y_seqs = []\n",
        "    for i in range(len(data_numerical_encoded) - sequence_length):\n",
        "        numerical_seq = data_numerical_encoded[i:i + sequence_length]\n",
        "        type_seq = data_type_encoded[i:i + sequence_length]\n",
        "        origin_seq = origin_ids[i:i + sequence_length]\n",
        "        dest_seq = dest_ids[i:i + sequence_length]\n",
        "        combined_seq = np.concatenate([numerical_seq, type_seq, origin_seq, dest_seq], axis=1) # Combine features\n",
        "        target = data_numerical_encoded[i + sequence_length]\n",
        "        y_val = y[i:i + sequence_length]\n",
        "        sequences.append(combined_seq)\n",
        "        targets.append(target)\n",
        "        y_seqs.append(y_val)\n",
        "    return np.array(sequences), np.array(targets), np.array(y_seqs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9jvx0rSYej2"
      },
      "outputs": [],
      "source": [
        "numerical_encoded = scaler.transform(financial_data_df[numerical_features]) # Ensure scaling is done before sequence creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3KwGLnkdJNW"
      },
      "outputs": [],
      "source": [
        "X_seq, y_next, y_fraud_seq = create_sequences_with_ids(\n",
        "    numerical_encoded, type_encoded, padded_origin, padded_dest, y_fraud, sequence_length\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"X_seq.shape:\", X_seq.shape)\n",
        "print(\"y_next.shape:\", y_next.shape)\n",
        "print(\"y_fraud_seq.shape:\", y_fraud_seq.shape)\n",
        "y_next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxa9eoncZDnV"
      },
      "outputs": [],
      "source": [
        "# Split data into training and testing sets\n",
        "# First, get the sequence indices for origin and dest that match X_seq length\n",
        "origin_seq = origin_sequences[sequence_length:]\n",
        "dest_seq = dest_sequences[sequence_length:]\n",
        "\n",
        "# Now split the data with matching lengths\n",
        "X_train, X_test, y_train_fraud, y_test_fraud, origin_train, origin_test, dest_train, dest_test = train_test_split(\n",
        "    X_seq,\n",
        "    y_fraud_seq,\n",
        "    origin_seq,\n",
        "    dest_seq,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"X_train.shape:\", X_train.shape)\n",
        "print(\"X_test.shape:\", X_test.shape)\n",
        "print(\"y_train_fraud.shape:\", y_train_fraud.shape)\n",
        "print(\"y_test_fraud.shape:\", y_test_fraud.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJLNdACad14A"
      },
      "outputs": [],
      "source": [
        "embedding_dim=50 \n",
        "n_numerical_features = len(numerical_features)\n",
        "n_type_features = type_encoded.shape[1]\n",
        "\n",
        "input_numerical = Input(shape=(sequence_length, n_numerical_features), name='numerical_input')\n",
        "input_type = Input(shape=(sequence_length, n_type_features), name='type_input')\n",
        "input_origin = Input(shape=(sequence_length, 1), name='origin_input')\n",
        "input_dest = Input(shape=(sequence_length, 1), name='dest_input')\n",
        "\n",
        "embedding_origin = Embedding(input_dim=max_origin_features, output_dim=embedding_dim, input_length=sequence_length)(input_origin)\n",
        "embedding_dest = Embedding(input_dim=max_dest_features, output_dim=embedding_dim, input_length=sequence_length)(input_dest)\n",
        "\n",
        "# Reshape the embedding outputs to remove the extra dimension\n",
        "reshape_origin = Reshape((sequence_length, embedding_dim))(embedding_origin)\n",
        "reshape_dest = Reshape((sequence_length, embedding_dim))(embedding_dest)\n",
        "\n",
        "merged_input = Concatenate(axis=-1)([input_numerical, input_type, reshape_origin, reshape_dest])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"input_numerical:\", input_numerical.shape)\n",
        "print(\"input_type:\", input_type.shape)\n",
        "print(\"input_origin:\", input_origin.shape)\n",
        "print(\"input_dest:\", input_dest.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5ggRonCd58z"
      },
      "outputs": [],
      "source": [
        "# Encoder\n",
        "lstm_enc_1 = LSTM(128, activation='relu', return_sequences=True)(merged_input)\n",
        "lstm_enc_2 = LSTM(64, activation='relu', return_sequences=False)(lstm_enc_1)\n",
        "repeat_vector = RepeatVector(sequence_length)(lstm_enc_2)\n",
        "\n",
        "# Decoder\n",
        "lstm_dec_1 = LSTM(64, activation='relu', return_sequences=True)(repeat_vector)\n",
        "lstm_dec_2 = LSTM(128, activation='relu', return_sequences=True)(lstm_dec_1)\n",
        "output_numerical = TimeDistributed(Dense(n_numerical_features))(lstm_dec_2)\n",
        "output_type = TimeDistributed(Dense(n_type_features, activation='sigmoid'))(lstm_dec_2) # Assuming one-hot encoded\n",
        "\n",
        "autoencoder = Model(inputs=[input_numerical, input_type, input_origin, input_dest], outputs=[output_numerical, output_type])\n",
        "autoencoder.compile(optimizer='adam', loss=['mse', 'categorical_crossentropy']) # Adjust loss if needed\n",
        "\n",
        "print(autoencoder.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. TensorBoard Callback\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Early Stopping Callback\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#transorboard to visualize the model architecture\n",
        "#Visualize the model layers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(autoencoder, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Train the Model with Callbacks\n",
        "epochs = 5\n",
        "batch_size = 128\n",
        "history = autoencoder.fit(\n",
        "    X_train, X_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.1,\n",
        "    shuffle=False,\n",
        "    callbacks=[tensorboard_callback, early_stopping_callback],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Anomaly Detection\n",
        "X_train_pred = autoencoder.predict(X_train)\n",
        "train_mse = np.mean(np.square(X_train - X_train_pred), axis=(1, 2))\n",
        "\n",
        "X_test_pred = autoencoder.predict(X_test)\n",
        "test_mse = np.mean(np.square(X_test - X_test_pred), axis=(1, 2))\n",
        "\n",
        "threshold = np.percentile(train_mse, 95)\n",
        "anomalies = test_mse > threshold\n",
        "\n",
        "# 9. Evaluate Performance\n",
        "def plot_precision_recall(y_true, anomaly_scores):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, anomaly_scores)\n",
        "    auc_score = auc(recall, precision)\n",
        "    plt.plot(recall, precision, label=f'AUC = {auc_score:.2f}')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    return auc_score\n",
        "\n",
        "test_fraud_labels_aligned = y_test_fraud_seq[:, -1]\n",
        "plot_precision_recall(test_fraud_labels_aligned, test_mse)\n",
        "\n",
        "y_pred = (test_mse > threshold).astype(int)\n",
        "print(\"\\nClassification Report (based on threshold):\")\n",
        "print(classification_report(test_fraud_labels_aligned, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPtQZXnHGHSwMChmWnYE+fF",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
